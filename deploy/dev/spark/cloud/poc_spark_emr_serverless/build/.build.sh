# -- Inputs

PYTHON_VERSION="3.9.12"
PYTHON_VERSION_SHORT="3.9"
POETRY_VERSION="1.2.0b3"
S3_BUCKET="poc-spark-emr-serverless-dev-bucket-7cb2462"

echo "Inputs to deploy Spark cloud env to s3:"
echo "PYTHON_VERSION=$PYTHON_VERSION"
echo "PYTHON_VERSION_SHORT=$PYTHON_VERSION_SHORT"
echo "POETRY_VERSION=$POETRY_VERSION"
echo "S3_BUCKET=$S3_BUCKET"

# -- Build the custom venv and package wheel files from Poetry in Docker (with BuildKit backend)

echo "Building the custom venv and package wheel files from Poetry in Docker (with BuildKit backend)"
DOCKER_BUILDKIT=1 docker build \
  --build-arg PYTHON_VERSION="${PYTHON_VERSION}" \
  --build-arg PYTHON_VERSION_SHORT="${PYTHON_VERSION_SHORT}" \
  --build-arg POETRY_VERSION="${POETRY_VERSION}" \
  -f deploy/dev/spark/cloud/poc_spark_emr_serverless/build/Dockerfile \
  --output . .

# -- Upload the virtual environment to S3

echo "Uploading the virtual environment to S3"
aws s3 cp deploy/dev/spark/cloud/poc_spark_emr_serverless/build/artifacts/venvs/pyspark_${PYTHON_VERSION}.tar.gz s3://${S3_BUCKET}/artifacts/venvs/

# -- Upload the wheel file to S3

echo "Retrieving Poetry wheel file already generated by Poetry in Docker"
script="deploy/dev/spark/cloud/poc_spark_emr_serverless/build/get_poetry_package_wheel_file.py"
function="get_poetry_wheel_file"
python_run_command="poetry run python3 $script $function"
echo "Python command to get the wheel file: $python_run_command"
wheel_file_path=$($python_run_command)
echo "Wheel file found: $wheel_file_path"

echo "Uploading the wheel file to S3"
aws s3 cp ${wheel_file_path} s3://${S3_BUCKET}/artifacts/package_wheel_files/

